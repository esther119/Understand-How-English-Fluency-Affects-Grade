{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "#Import all the dependencies\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lexcial_rich_data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polls ID</th>\n",
       "      <th>Poll Responses Response</th>\n",
       "      <th>Assessment reports Hashtag</th>\n",
       "      <th>Assessment reports Score</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>tokenized_responses</th>\n",
       "      <th>stemmed_responses</th>\n",
       "      <th>clean_responses</th>\n",
       "      <th>string</th>\n",
       "      <th>LOs/ HCs</th>\n",
       "      <th>...</th>\n",
       "      <th>Summer</th>\n",
       "      <th>Dugast</th>\n",
       "      <th>words_count</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>ttr</th>\n",
       "      <th>rttr</th>\n",
       "      <th>cttr</th>\n",
       "      <th>mtld</th>\n",
       "      <th>herdan</th>\n",
       "      <th>maas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12522</td>\n",
       "      <td>The strengths of Plato's approach is his const...</td>\n",
       "      <td>#objectivemorality</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['The', 'strengths', 'of', \"Plato's\", 'approac...</td>\n",
       "      <td>['the', 'strength', 'of', 'plato', 'approach',...</td>\n",
       "      <td>['strength', 'plato', 'approach', 'construct',...</td>\n",
       "      <td>strength plato approach construct whole framew...</td>\n",
       "      <td>objmorality</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967595</td>\n",
       "      <td>90.603405</td>\n",
       "      <td>51</td>\n",
       "      <td>43</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>6.021204</td>\n",
       "      <td>4.257634</td>\n",
       "      <td>91.035000</td>\n",
       "      <td>0.956604</td>\n",
       "      <td>0.011037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12522</td>\n",
       "      <td>In the breakout we discussed if outside the ca...</td>\n",
       "      <td>#objectivemorality</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>['In', 'the', 'breakout', 'we', 'discussed', '...</td>\n",
       "      <td>['in', 'the', 'breakout', 'we', 'discuss', 'if...</td>\n",
       "      <td>['breakout', 'discuss', 'outsid', 'cave', 'big...</td>\n",
       "      <td>breakout discuss outsid cave bigger cave thus ...</td>\n",
       "      <td>objmorality</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946879</td>\n",
       "      <td>56.677811</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>5.728312</td>\n",
       "      <td>4.050528</td>\n",
       "      <td>64.978667</td>\n",
       "      <td>0.928058</td>\n",
       "      <td>0.017644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12522</td>\n",
       "      <td>Back to cmmon confusion time: the section 'und...</td>\n",
       "      <td>#objectivemorality</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['Back', 'to', 'cmmon', 'confusion', 'time', '...</td>\n",
       "      <td>['back', 'to', 'cmmon', 'confus', 'time', 'the...</td>\n",
       "      <td>['back', 'cmmon', 'confus', 'time', 'section',...</td>\n",
       "      <td>back cmmon confus time section understand inte...</td>\n",
       "      <td>objmorality</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938242</td>\n",
       "      <td>47.879322</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>4.879954</td>\n",
       "      <td>3.450649</td>\n",
       "      <td>38.068807</td>\n",
       "      <td>0.921444</td>\n",
       "      <td>0.020886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12522</td>\n",
       "      <td>Most difficult weakness is that his position w...</td>\n",
       "      <td>#objectivemorality</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['Most', 'difficult', 'weakness', 'is', 'that'...</td>\n",
       "      <td>['most', 'difficult', 'weak', 'is', 'that', 'h...</td>\n",
       "      <td>['difficult', 'weak', 'posit', 'understand', '...</td>\n",
       "      <td>difficult weak posit understand testabl like i...</td>\n",
       "      <td>objmorality</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964056</td>\n",
       "      <td>80.343345</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>5.284229</td>\n",
       "      <td>3.736514</td>\n",
       "      <td>70.980000</td>\n",
       "      <td>0.954401</td>\n",
       "      <td>0.012447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12522</td>\n",
       "      <td>I'm still trying to understand the significanc...</td>\n",
       "      <td>#objectivemorality</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"I'm\", 'still', 'trying', 'to', 'understand',...</td>\n",
       "      <td>[\"i'm\", 'still', 'tri', 'to', 'understand', 't...</td>\n",
       "      <td>[\"i'm\", 'still', 'tri', 'understand', 'signifi...</td>\n",
       "      <td>i'm still tri understand signific cave analog ...</td>\n",
       "      <td>objmorality</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966813</td>\n",
       "      <td>87.158819</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>5.466082</td>\n",
       "      <td>3.865103</td>\n",
       "      <td>78.446667</td>\n",
       "      <td>0.957393</td>\n",
       "      <td>0.011473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Polls ID                            Poll Responses Response  \\\n",
       "0     12522  The strengths of Plato's approach is his const...   \n",
       "1     12522  In the breakout we discussed if outside the ca...   \n",
       "2     12522  Back to cmmon confusion time: the section 'und...   \n",
       "3     12522  Most difficult weakness is that his position w...   \n",
       "4     12522  I'm still trying to understand the significanc...   \n",
       "\n",
       "  Assessment reports Hashtag  Assessment reports Score  time_stamp  \\\n",
       "0         #objectivemorality                         2           1   \n",
       "1         #objectivemorality                         3           1   \n",
       "2         #objectivemorality                         2           1   \n",
       "3         #objectivemorality                         2           1   \n",
       "4         #objectivemorality                         2           1   \n",
       "\n",
       "                                 tokenized_responses  \\\n",
       "0  ['The', 'strengths', 'of', \"Plato's\", 'approac...   \n",
       "1  ['In', 'the', 'breakout', 'we', 'discussed', '...   \n",
       "2  ['Back', 'to', 'cmmon', 'confusion', 'time', '...   \n",
       "3  ['Most', 'difficult', 'weakness', 'is', 'that'...   \n",
       "4  [\"I'm\", 'still', 'trying', 'to', 'understand',...   \n",
       "\n",
       "                                   stemmed_responses  \\\n",
       "0  ['the', 'strength', 'of', 'plato', 'approach',...   \n",
       "1  ['in', 'the', 'breakout', 'we', 'discuss', 'if...   \n",
       "2  ['back', 'to', 'cmmon', 'confus', 'time', 'the...   \n",
       "3  ['most', 'difficult', 'weak', 'is', 'that', 'h...   \n",
       "4  [\"i'm\", 'still', 'tri', 'to', 'understand', 't...   \n",
       "\n",
       "                                     clean_responses  \\\n",
       "0  ['strength', 'plato', 'approach', 'construct',...   \n",
       "1  ['breakout', 'discuss', 'outsid', 'cave', 'big...   \n",
       "2  ['back', 'cmmon', 'confus', 'time', 'section',...   \n",
       "3  ['difficult', 'weak', 'posit', 'understand', '...   \n",
       "4  [\"i'm\", 'still', 'tri', 'understand', 'signifi...   \n",
       "\n",
       "                                              string     LOs/ HCs  ...  \\\n",
       "0  strength plato approach construct whole framew...  objmorality  ...   \n",
       "1  breakout discuss outsid cave bigger cave thus ...  objmorality  ...   \n",
       "2  back cmmon confus time section understand inte...  objmorality  ...   \n",
       "3  difficult weak posit understand testabl like i...  objmorality  ...   \n",
       "4  i'm still tri understand signific cave analog ...  objmorality  ...   \n",
       "\n",
       "     Summer     Dugast  words_count  unique_words       ttr      rttr  \\\n",
       "0  0.967595  90.603405           51            43  0.843137  6.021204   \n",
       "1  0.946879  56.677811           59            44  0.745763  5.728312   \n",
       "2  0.938242  47.879322           43            32  0.744186  4.879954   \n",
       "3  0.964056  80.343345           39            33  0.846154  5.284229   \n",
       "4  0.966813  87.158819           41            35  0.853659  5.466082   \n",
       "\n",
       "       cttr       mtld    herdan      maas  \n",
       "0  4.257634  91.035000  0.956604  0.011037  \n",
       "1  4.050528  64.978667  0.928058  0.017644  \n",
       "2  3.450649  38.068807  0.921444  0.020886  \n",
       "3  3.736514  70.980000  0.954401  0.012447  \n",
       "4  3.865103  78.446667  0.957393  0.011473  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only take when the column isn't NaN \n",
    "df = df[df['string'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "df_string = df.string\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d), tags=[str(i)]) for i, _d in enumerate(df_string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 10\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['strength', 'plato', 'approach', 'construct', 'whole', 'framework', 'matt', 'answer', 'preparatori', 'poll', 'focus', 'specif', 'moral', 'knowledg', 'instead', 'set', 'form', 'good', 'framework', 'veri', 'hard', 'attack', 'weak', 'abstract'], tags=['0']),\n",
       " TaggedDocument(words=['breakout', 'discuss', 'outsid', 'cave', 'bigger', 'cave', 'thus', 'abl', 'illumin', 'howev', 'still', 'stuck', 'know', 'left', 'cave', 'matt', 'said', 'doesnt', 'matter', 'moral', 'knowledg', 'dont', 'need', 'prove', 'pursu'], tags=['1']),\n",
       " TaggedDocument(words=['back', 'cmmon', 'confus', 'time', 'section', 'understand', 'intellig', 'tabl', 'suppos', 'equat', 'knowledg', 'knowledg', 'suppos', 'object', 'true', 'differ', 'moral', 'object', 'moral', 'knowledg', 'question', 'rais', 'rosi', 'follow'], tags=['2']),\n",
       " TaggedDocument(words=['difficult', 'weak', 'posit', 'understand', 'testabl', 'like', 'incomprehens', 'peopl', 'struggl', 'quit', 'lot', 'decid', 'whether', 'ani', 'way', 'get', 'cave'], tags=['3']),\n",
       " TaggedDocument(words=['i', \"'m\", 'still', 'tri', 'understand', 'signific', 'cave', 'analog', 'whi', 'long', 'stand', 'profound', 'refer', 'debat', 'certain', 'help', 'show', 'much', 'dig', 'seem', 'strength', 'though'], tags=['4']),\n",
       " TaggedDocument(words=['neologis', 'term', 'cavecept', 'mean', 'even', 'leav', 'cave', 'stuck', 'concentr', 'circl', 'mani', 'cave', 'never', 'know', 'point', 'left', 'cave', 'knowledg', 'like', 'number', 'dont', 'know', 'last', 'number', 'infinit', 'ever', 'leav', 'cave'], tags=['5']),\n",
       " TaggedDocument(words=['difficult', 'grasp', 'appli', 'plato', 'divis', 'intelligibel', 'real', 'part', 'find', 'moral', 'knowledg', 'potenti', 'teach', 'plato', 'alway', 'receiv', 'pessim', 'abl', 'find', 'truth', 'pass', 'know', 'find', 'form', 'good', 'possibl'], tags=['6']),\n",
       " TaggedDocument(words=['hierarchi', 'chart', 'fill', 'begin', 'class', 'moral', 'knowledg', 'object', 'clear', 'explain', 'hard', 'understand', 'first', 'w', 'refer', 'chart', 'plato', 'term', 'truth', 'clear', 'relat', 'form', 'ask', 'q'], tags=['7']),\n",
       " TaggedDocument(words=['one', 'know', 'cave', 'one', 'doe', 'know', 'get', 'motiv', 'approach', 'get', 'cave', 'someth', 'testabl', 'bit', 'confus'], tags=['8']),\n",
       " TaggedDocument(words=['breakout', 'group', 'xiaon', 'claim', 'cave', 'becaus', 'evid', 'we', \"'\", 'r', 'cave', 'think', 'realli', 'interest', 'exampl', 'cave', 'prision', 'evid', 'they', \"'\", 'r', 'see', 'realiti', 'hard', 'becuas', 'qus', 'everyth'], tags=['9'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(max_epochs):\n",
    "    # print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=10)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "- How to tune a model? 16 min for 10 epoch \n",
    "\n",
    "- `model.dv.get_vector(key, norm=True)` key is the tagged key number \n",
    "\n",
    "- run get vector from 0 - 10, get the list and append it in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176141, 176141)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_list = pd.Series([model.dv.get_vector(i, norm=True) for i in range(len(df))]).T\n",
    "len(tagged_data), len(vectors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polls ID</th>\n",
       "      <th>Poll Responses Response</th>\n",
       "      <th>Assessment reports Hashtag</th>\n",
       "      <th>Assessment reports Score</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>tokenized_responses</th>\n",
       "      <th>stemmed_responses</th>\n",
       "      <th>clean_responses</th>\n",
       "      <th>string</th>\n",
       "      <th>LOs/ HCs</th>\n",
       "      <th>...</th>\n",
       "      <th>Dugast</th>\n",
       "      <th>words_count</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>ttr</th>\n",
       "      <th>rttr</th>\n",
       "      <th>cttr</th>\n",
       "      <th>mtld</th>\n",
       "      <th>herdan</th>\n",
       "      <th>maas</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12522</td>\n",
       "      <td>The strengths of Plato's approach is his const...</td>\n",
       "      <td>#objectivemorality</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['The', 'strengths', 'of', \"Plato's\", 'approac...</td>\n",
       "      <td>['the', 'strength', 'of', 'plato', 'approach',...</td>\n",
       "      <td>['strength', 'plato', 'approach', 'construct',...</td>\n",
       "      <td>strength plato approach construct whole framew...</td>\n",
       "      <td>objmorality</td>\n",
       "      <td>...</td>\n",
       "      <td>90.603405</td>\n",
       "      <td>51</td>\n",
       "      <td>43</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>6.021204</td>\n",
       "      <td>4.257634</td>\n",
       "      <td>91.035000</td>\n",
       "      <td>0.956604</td>\n",
       "      <td>0.011037</td>\n",
       "      <td>[0.2852866, 0.10944329, 0.12894145, 0.04560305...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12522</td>\n",
       "      <td>In the breakout we discussed if outside the ca...</td>\n",
       "      <td>#objectivemorality</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>['In', 'the', 'breakout', 'we', 'discussed', '...</td>\n",
       "      <td>['in', 'the', 'breakout', 'we', 'discuss', 'if...</td>\n",
       "      <td>['breakout', 'discuss', 'outsid', 'cave', 'big...</td>\n",
       "      <td>breakout discuss outsid cave bigger cave thus ...</td>\n",
       "      <td>objmorality</td>\n",
       "      <td>...</td>\n",
       "      <td>56.677811</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>5.728312</td>\n",
       "      <td>4.050528</td>\n",
       "      <td>64.978667</td>\n",
       "      <td>0.928058</td>\n",
       "      <td>0.017644</td>\n",
       "      <td>[0.40190294, 0.21657851, -0.058513626, 0.16431...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12522</td>\n",
       "      <td>Back to cmmon confusion time: the section 'und...</td>\n",
       "      <td>#objectivemorality</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['Back', 'to', 'cmmon', 'confusion', 'time', '...</td>\n",
       "      <td>['back', 'to', 'cmmon', 'confus', 'time', 'the...</td>\n",
       "      <td>['back', 'cmmon', 'confus', 'time', 'section',...</td>\n",
       "      <td>back cmmon confus time section understand inte...</td>\n",
       "      <td>objmorality</td>\n",
       "      <td>...</td>\n",
       "      <td>47.879322</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>4.879954</td>\n",
       "      <td>3.450649</td>\n",
       "      <td>38.068807</td>\n",
       "      <td>0.921444</td>\n",
       "      <td>0.020886</td>\n",
       "      <td>[0.36874977, -0.020495353, 0.121122204, -0.052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12522</td>\n",
       "      <td>Most difficult weakness is that his position w...</td>\n",
       "      <td>#objectivemorality</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['Most', 'difficult', 'weakness', 'is', 'that'...</td>\n",
       "      <td>['most', 'difficult', 'weak', 'is', 'that', 'h...</td>\n",
       "      <td>['difficult', 'weak', 'posit', 'understand', '...</td>\n",
       "      <td>difficult weak posit understand testabl like i...</td>\n",
       "      <td>objmorality</td>\n",
       "      <td>...</td>\n",
       "      <td>80.343345</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>5.284229</td>\n",
       "      <td>3.736514</td>\n",
       "      <td>70.980000</td>\n",
       "      <td>0.954401</td>\n",
       "      <td>0.012447</td>\n",
       "      <td>[0.28095677, 0.32379583, 0.31731528, 0.0348413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12522</td>\n",
       "      <td>I'm still trying to understand the significanc...</td>\n",
       "      <td>#objectivemorality</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"I'm\", 'still', 'trying', 'to', 'understand',...</td>\n",
       "      <td>[\"i'm\", 'still', 'tri', 'to', 'understand', 't...</td>\n",
       "      <td>[\"i'm\", 'still', 'tri', 'understand', 'signifi...</td>\n",
       "      <td>i'm still tri understand signific cave analog ...</td>\n",
       "      <td>objmorality</td>\n",
       "      <td>...</td>\n",
       "      <td>87.158819</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>5.466082</td>\n",
       "      <td>3.865103</td>\n",
       "      <td>78.446667</td>\n",
       "      <td>0.957393</td>\n",
       "      <td>0.011473</td>\n",
       "      <td>[0.19043194, 0.059316073, 0.11514729, 0.262181...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176136</th>\n",
       "      <td>320721</td>\n",
       "      <td>(a) For &lt;s&gt; =  each of the energy term is redu...</td>\n",
       "      <td>#IsingModel</td>\n",
       "      <td>4</td>\n",
       "      <td>15312</td>\n",
       "      <td>['a', 'For', 's', 'each', 'of', 'the', 'energy...</td>\n",
       "      <td>['a', 'for', 's', 'each', 'of', 'the', 'energi...</td>\n",
       "      <td>['energi', 'term', 'reduc', 'partit', 'functio...</td>\n",
       "      <td>energi term reduc partit function entir system...</td>\n",
       "      <td>isingmodel</td>\n",
       "      <td>...</td>\n",
       "      <td>41.516305</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>50.852273</td>\n",
       "      <td>0.889076</td>\n",
       "      <td>0.024087</td>\n",
       "      <td>[0.31073844, 0.45755118, 0.09429593, -0.086379...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176137</th>\n",
       "      <td>320721</td>\n",
       "      <td>) When &lt;s&gt;!=, then cosh(x) &gt;  so function insi...</td>\n",
       "      <td>#IsingModel</td>\n",
       "      <td>4</td>\n",
       "      <td>15312</td>\n",
       "      <td>['When', 's', 'then', 'cosh', 'x', 'so', 'func...</td>\n",
       "      <td>['when', 's', 'then', 'cosh', 'x', 'so', 'func...</td>\n",
       "      <td>['cosh', 'x', 'function', 'insid', 'log', 'hig...</td>\n",
       "      <td>cosh x function insid log higher magnitud magn...</td>\n",
       "      <td>isingmodel</td>\n",
       "      <td>...</td>\n",
       "      <td>46.999818</td>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5.422177</td>\n",
       "      <td>3.834058</td>\n",
       "      <td>47.659963</td>\n",
       "      <td>0.912886</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>[0.5535098, 0.014367881, 0.39884728, 0.0066604...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176138</th>\n",
       "      <td>320721</td>\n",
       "      <td>Emailed it to you earlier. The explanation in ...</td>\n",
       "      <td>#IsingModel</td>\n",
       "      <td>4</td>\n",
       "      <td>15312</td>\n",
       "      <td>['Emailed', 'it', 'to', 'you', 'earlier', 'The...</td>\n",
       "      <td>['email', 'it', 'to', 'you', 'earlier', 'the',...</td>\n",
       "      <td>['email', 'earlier', 'explan', 'cosh', 'expres...</td>\n",
       "      <td>email earlier explan cosh express larger one t...</td>\n",
       "      <td>isingmodel</td>\n",
       "      <td>...</td>\n",
       "      <td>67.845993</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>5.124101</td>\n",
       "      <td>3.623287</td>\n",
       "      <td>60.840000</td>\n",
       "      <td>0.946002</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>[0.37874267, 0.15700613, 0.34322095, 0.1536443...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176139</th>\n",
       "      <td>320721</td>\n",
       "      <td>. The free energy is F=-NkT*ln(*cosh(dj*beta*&lt;...</td>\n",
       "      <td>#IsingModel</td>\n",
       "      <td>4</td>\n",
       "      <td>15312</td>\n",
       "      <td>['The', 'free', 'energy', 'is', 'F', 'NkT', 'l...</td>\n",
       "      <td>['the', 'free', 'energi', 'is', 'f', 'nkt', 'l...</td>\n",
       "      <td>['free', 'energi', 'f', 'nkt', 'ln', 'cosh', '...</td>\n",
       "      <td>free energi f nkt ln cosh dj beta h thus unmag...</td>\n",
       "      <td>isingmodel</td>\n",
       "      <td>...</td>\n",
       "      <td>38.752118</td>\n",
       "      <td>87</td>\n",
       "      <td>52</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>5.574985</td>\n",
       "      <td>3.942110</td>\n",
       "      <td>38.993785</td>\n",
       "      <td>0.884757</td>\n",
       "      <td>0.025805</td>\n",
       "      <td>[0.3784142, 0.1563193, 0.24713087, 0.13442542,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176140</th>\n",
       "      <td>321089</td>\n",
       "      <td>I had seen some of these concepts before, but ...</td>\n",
       "      <td>#IsingModel</td>\n",
       "      <td>4</td>\n",
       "      <td>15334</td>\n",
       "      <td>['I', 'had', 'seen', 'some', 'of', 'these', 'c...</td>\n",
       "      <td>['i', 'had', 'seen', 'some', 'of', 'these', 'c...</td>\n",
       "      <td>['seen', 'concept', 'befor', 'complet', 'rigor...</td>\n",
       "      <td>seen concept befor complet rigor grasp though ...</td>\n",
       "      <td>isingmodel</td>\n",
       "      <td>...</td>\n",
       "      <td>62.653332</td>\n",
       "      <td>93</td>\n",
       "      <td>67</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>6.947576</td>\n",
       "      <td>4.912678</td>\n",
       "      <td>88.651386</td>\n",
       "      <td>0.927656</td>\n",
       "      <td>0.015961</td>\n",
       "      <td>[-0.24099706, 0.03135745, 0.28181472, -0.30574...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176141 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Polls ID                            Poll Responses Response  \\\n",
       "0          12522  The strengths of Plato's approach is his const...   \n",
       "1          12522  In the breakout we discussed if outside the ca...   \n",
       "2          12522  Back to cmmon confusion time: the section 'und...   \n",
       "3          12522  Most difficult weakness is that his position w...   \n",
       "4          12522  I'm still trying to understand the significanc...   \n",
       "...          ...                                                ...   \n",
       "176136    320721  (a) For <s> =  each of the energy term is redu...   \n",
       "176137    320721  ) When <s>!=, then cosh(x) >  so function insi...   \n",
       "176138    320721  Emailed it to you earlier. The explanation in ...   \n",
       "176139    320721  . The free energy is F=-NkT*ln(*cosh(dj*beta*<...   \n",
       "176140    321089  I had seen some of these concepts before, but ...   \n",
       "\n",
       "       Assessment reports Hashtag  Assessment reports Score  time_stamp  \\\n",
       "0              #objectivemorality                         2           1   \n",
       "1              #objectivemorality                         3           1   \n",
       "2              #objectivemorality                         2           1   \n",
       "3              #objectivemorality                         2           1   \n",
       "4              #objectivemorality                         2           1   \n",
       "...                           ...                       ...         ...   \n",
       "176136                #IsingModel                         4       15312   \n",
       "176137                #IsingModel                         4       15312   \n",
       "176138                #IsingModel                         4       15312   \n",
       "176139                #IsingModel                         4       15312   \n",
       "176140                #IsingModel                         4       15334   \n",
       "\n",
       "                                      tokenized_responses  \\\n",
       "0       ['The', 'strengths', 'of', \"Plato's\", 'approac...   \n",
       "1       ['In', 'the', 'breakout', 'we', 'discussed', '...   \n",
       "2       ['Back', 'to', 'cmmon', 'confusion', 'time', '...   \n",
       "3       ['Most', 'difficult', 'weakness', 'is', 'that'...   \n",
       "4       [\"I'm\", 'still', 'trying', 'to', 'understand',...   \n",
       "...                                                   ...   \n",
       "176136  ['a', 'For', 's', 'each', 'of', 'the', 'energy...   \n",
       "176137  ['When', 's', 'then', 'cosh', 'x', 'so', 'func...   \n",
       "176138  ['Emailed', 'it', 'to', 'you', 'earlier', 'The...   \n",
       "176139  ['The', 'free', 'energy', 'is', 'F', 'NkT', 'l...   \n",
       "176140  ['I', 'had', 'seen', 'some', 'of', 'these', 'c...   \n",
       "\n",
       "                                        stemmed_responses  \\\n",
       "0       ['the', 'strength', 'of', 'plato', 'approach',...   \n",
       "1       ['in', 'the', 'breakout', 'we', 'discuss', 'if...   \n",
       "2       ['back', 'to', 'cmmon', 'confus', 'time', 'the...   \n",
       "3       ['most', 'difficult', 'weak', 'is', 'that', 'h...   \n",
       "4       [\"i'm\", 'still', 'tri', 'to', 'understand', 't...   \n",
       "...                                                   ...   \n",
       "176136  ['a', 'for', 's', 'each', 'of', 'the', 'energi...   \n",
       "176137  ['when', 's', 'then', 'cosh', 'x', 'so', 'func...   \n",
       "176138  ['email', 'it', 'to', 'you', 'earlier', 'the',...   \n",
       "176139  ['the', 'free', 'energi', 'is', 'f', 'nkt', 'l...   \n",
       "176140  ['i', 'had', 'seen', 'some', 'of', 'these', 'c...   \n",
       "\n",
       "                                          clean_responses  \\\n",
       "0       ['strength', 'plato', 'approach', 'construct',...   \n",
       "1       ['breakout', 'discuss', 'outsid', 'cave', 'big...   \n",
       "2       ['back', 'cmmon', 'confus', 'time', 'section',...   \n",
       "3       ['difficult', 'weak', 'posit', 'understand', '...   \n",
       "4       [\"i'm\", 'still', 'tri', 'understand', 'signifi...   \n",
       "...                                                   ...   \n",
       "176136  ['energi', 'term', 'reduc', 'partit', 'functio...   \n",
       "176137  ['cosh', 'x', 'function', 'insid', 'log', 'hig...   \n",
       "176138  ['email', 'earlier', 'explan', 'cosh', 'expres...   \n",
       "176139  ['free', 'energi', 'f', 'nkt', 'ln', 'cosh', '...   \n",
       "176140  ['seen', 'concept', 'befor', 'complet', 'rigor...   \n",
       "\n",
       "                                                   string     LOs/ HCs  ...  \\\n",
       "0       strength plato approach construct whole framew...  objmorality  ...   \n",
       "1       breakout discuss outsid cave bigger cave thus ...  objmorality  ...   \n",
       "2       back cmmon confus time section understand inte...  objmorality  ...   \n",
       "3       difficult weak posit understand testabl like i...  objmorality  ...   \n",
       "4       i'm still tri understand signific cave analog ...  objmorality  ...   \n",
       "...                                                   ...          ...  ...   \n",
       "176136  energi term reduc partit function entir system...   isingmodel  ...   \n",
       "176137  cosh x function insid log higher magnitud magn...   isingmodel  ...   \n",
       "176138  email earlier explan cosh express larger one t...   isingmodel  ...   \n",
       "176139  free energi f nkt ln cosh dj beta h thus unmag...   isingmodel  ...   \n",
       "176140  seen concept befor complet rigor grasp though ...   isingmodel  ...   \n",
       "\n",
       "           Dugast words_count  unique_words       ttr      rttr      cttr  \\\n",
       "0       90.603405          51            43  0.843137  6.021204  4.257634   \n",
       "1       56.677811          59            44  0.745763  5.728312  4.050528   \n",
       "2       47.879322          43            32  0.744186  4.879954  3.450649   \n",
       "3       80.343345          39            33  0.846154  5.284229  3.736514   \n",
       "4       87.158819          41            35  0.853659  5.466082  3.865103   \n",
       "...           ...         ...           ...       ...       ...       ...   \n",
       "176136  41.516305         100            60  0.600000  6.000000  4.242641   \n",
       "176137  46.999818          60            42  0.700000  5.422177  3.834058   \n",
       "176138  67.845993          39            32  0.820513  5.124101  3.623287   \n",
       "176139  38.752118          87            52  0.597701  5.574985  3.942110   \n",
       "176140  62.653332          93            67  0.720430  6.947576  4.912678   \n",
       "\n",
       "             mtld    herdan      maas  \\\n",
       "0       91.035000  0.956604  0.011037   \n",
       "1       64.978667  0.928058  0.017644   \n",
       "2       38.068807  0.921444  0.020886   \n",
       "3       70.980000  0.954401  0.012447   \n",
       "4       78.446667  0.957393  0.011473   \n",
       "...           ...       ...       ...   \n",
       "176136  50.852273  0.889076  0.024087   \n",
       "176137  47.659963  0.912886  0.021277   \n",
       "176138  60.840000  0.946002  0.014739   \n",
       "176139  38.993785  0.884757  0.025805   \n",
       "176140  88.651386  0.927656  0.015961   \n",
       "\n",
       "                                                      vec  \n",
       "0       [0.2852866, 0.10944329, 0.12894145, 0.04560305...  \n",
       "1       [0.40190294, 0.21657851, -0.058513626, 0.16431...  \n",
       "2       [0.36874977, -0.020495353, 0.121122204, -0.052...  \n",
       "3       [0.28095677, 0.32379583, 0.31731528, 0.0348413...  \n",
       "4       [0.19043194, 0.059316073, 0.11514729, 0.262181...  \n",
       "...                                                   ...  \n",
       "176136  [0.31073844, 0.45755118, 0.09429593, -0.086379...  \n",
       "176137  [0.5535098, 0.014367881, 0.39884728, 0.0066604...  \n",
       "176138  [0.37874267, 0.15700613, 0.34322095, 0.1536443...  \n",
       "176139  [0.3784142, 0.1563193, 0.24713087, 0.13442542,...  \n",
       "176140  [-0.24099706, 0.03135745, 0.28181472, -0.30574...  \n",
       "\n",
       "[176141 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# vectors_list = pd.Series([model.dv.get_vector(i, norm=True) for i in range(len(df))]).T\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['vec'] = vectors_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vec_1</th>\n",
       "      <th>vec_2</th>\n",
       "      <th>vec_3</th>\n",
       "      <th>vec_4</th>\n",
       "      <th>vec_5</th>\n",
       "      <th>vec_6</th>\n",
       "      <th>vec_7</th>\n",
       "      <th>vec_8</th>\n",
       "      <th>vec_9</th>\n",
       "      <th>vec_10</th>\n",
       "      <th>vec_11</th>\n",
       "      <th>vec_12</th>\n",
       "      <th>vec_13</th>\n",
       "      <th>vec_14</th>\n",
       "      <th>vec_15</th>\n",
       "      <th>vec_16</th>\n",
       "      <th>vec_17</th>\n",
       "      <th>vec_18</th>\n",
       "      <th>vec_19</th>\n",
       "      <th>vec_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.285287</td>\n",
       "      <td>0.109443</td>\n",
       "      <td>0.128941</td>\n",
       "      <td>0.045603</td>\n",
       "      <td>-0.073157</td>\n",
       "      <td>-0.508928</td>\n",
       "      <td>-0.077453</td>\n",
       "      <td>0.125095</td>\n",
       "      <td>0.164354</td>\n",
       "      <td>0.147681</td>\n",
       "      <td>0.227378</td>\n",
       "      <td>0.228062</td>\n",
       "      <td>-0.065646</td>\n",
       "      <td>-0.018259</td>\n",
       "      <td>0.589725</td>\n",
       "      <td>0.165162</td>\n",
       "      <td>0.243406</td>\n",
       "      <td>0.041697</td>\n",
       "      <td>0.047487</td>\n",
       "      <td>-0.080301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.401903</td>\n",
       "      <td>0.216579</td>\n",
       "      <td>-0.058514</td>\n",
       "      <td>0.164316</td>\n",
       "      <td>-0.153253</td>\n",
       "      <td>-0.301076</td>\n",
       "      <td>-0.462487</td>\n",
       "      <td>0.327744</td>\n",
       "      <td>0.033768</td>\n",
       "      <td>0.122843</td>\n",
       "      <td>0.067890</td>\n",
       "      <td>-0.172406</td>\n",
       "      <td>-0.026694</td>\n",
       "      <td>-0.313533</td>\n",
       "      <td>0.335412</td>\n",
       "      <td>-0.184949</td>\n",
       "      <td>-0.000822</td>\n",
       "      <td>0.093128</td>\n",
       "      <td>0.022665</td>\n",
       "      <td>0.142223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.368750</td>\n",
       "      <td>-0.020495</td>\n",
       "      <td>0.121122</td>\n",
       "      <td>-0.052415</td>\n",
       "      <td>-0.222401</td>\n",
       "      <td>-0.037515</td>\n",
       "      <td>-0.128381</td>\n",
       "      <td>0.011114</td>\n",
       "      <td>-0.065411</td>\n",
       "      <td>0.389529</td>\n",
       "      <td>0.172736</td>\n",
       "      <td>0.221275</td>\n",
       "      <td>0.215809</td>\n",
       "      <td>-0.060970</td>\n",
       "      <td>0.372512</td>\n",
       "      <td>-0.060175</td>\n",
       "      <td>0.251572</td>\n",
       "      <td>0.366057</td>\n",
       "      <td>0.229787</td>\n",
       "      <td>0.318017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.280957</td>\n",
       "      <td>0.323796</td>\n",
       "      <td>0.317315</td>\n",
       "      <td>0.034841</td>\n",
       "      <td>-0.129726</td>\n",
       "      <td>-0.239208</td>\n",
       "      <td>-0.543972</td>\n",
       "      <td>0.237506</td>\n",
       "      <td>0.026008</td>\n",
       "      <td>-0.006228</td>\n",
       "      <td>0.134589</td>\n",
       "      <td>-0.047511</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>-0.222005</td>\n",
       "      <td>0.227974</td>\n",
       "      <td>-0.272034</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>-0.173518</td>\n",
       "      <td>0.228723</td>\n",
       "      <td>0.078310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.190432</td>\n",
       "      <td>0.059316</td>\n",
       "      <td>0.115147</td>\n",
       "      <td>0.262182</td>\n",
       "      <td>-0.142157</td>\n",
       "      <td>-0.138226</td>\n",
       "      <td>-0.540430</td>\n",
       "      <td>0.141701</td>\n",
       "      <td>0.132393</td>\n",
       "      <td>0.052895</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.092645</td>\n",
       "      <td>-0.150749</td>\n",
       "      <td>-0.375577</td>\n",
       "      <td>-0.011666</td>\n",
       "      <td>-0.353730</td>\n",
       "      <td>0.131935</td>\n",
       "      <td>-0.431555</td>\n",
       "      <td>0.036446</td>\n",
       "      <td>-0.056576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176136</th>\n",
       "      <td>0.310738</td>\n",
       "      <td>0.457551</td>\n",
       "      <td>0.094296</td>\n",
       "      <td>-0.086379</td>\n",
       "      <td>0.198949</td>\n",
       "      <td>0.233082</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.091956</td>\n",
       "      <td>-0.338310</td>\n",
       "      <td>0.011298</td>\n",
       "      <td>-0.097236</td>\n",
       "      <td>-0.065367</td>\n",
       "      <td>-0.017717</td>\n",
       "      <td>0.070351</td>\n",
       "      <td>0.154885</td>\n",
       "      <td>0.079737</td>\n",
       "      <td>0.070983</td>\n",
       "      <td>-0.205526</td>\n",
       "      <td>-0.456746</td>\n",
       "      <td>-0.394401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176137</th>\n",
       "      <td>0.553510</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.398847</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.391471</td>\n",
       "      <td>0.252734</td>\n",
       "      <td>-0.076756</td>\n",
       "      <td>0.109708</td>\n",
       "      <td>-0.220743</td>\n",
       "      <td>0.096808</td>\n",
       "      <td>-0.091754</td>\n",
       "      <td>-0.265362</td>\n",
       "      <td>-0.044340</td>\n",
       "      <td>0.019195</td>\n",
       "      <td>0.226361</td>\n",
       "      <td>0.026845</td>\n",
       "      <td>0.016040</td>\n",
       "      <td>-0.111859</td>\n",
       "      <td>-0.303012</td>\n",
       "      <td>-0.058567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176138</th>\n",
       "      <td>0.378743</td>\n",
       "      <td>0.157006</td>\n",
       "      <td>0.343221</td>\n",
       "      <td>0.153644</td>\n",
       "      <td>0.187442</td>\n",
       "      <td>0.171272</td>\n",
       "      <td>0.170918</td>\n",
       "      <td>0.230688</td>\n",
       "      <td>-0.344162</td>\n",
       "      <td>0.292506</td>\n",
       "      <td>0.147863</td>\n",
       "      <td>0.147491</td>\n",
       "      <td>0.129362</td>\n",
       "      <td>-0.222961</td>\n",
       "      <td>0.042992</td>\n",
       "      <td>-0.094266</td>\n",
       "      <td>0.091049</td>\n",
       "      <td>-0.224582</td>\n",
       "      <td>0.175517</td>\n",
       "      <td>-0.359527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176139</th>\n",
       "      <td>0.378414</td>\n",
       "      <td>0.156319</td>\n",
       "      <td>0.247131</td>\n",
       "      <td>0.134425</td>\n",
       "      <td>0.170150</td>\n",
       "      <td>0.331544</td>\n",
       "      <td>0.077468</td>\n",
       "      <td>0.055609</td>\n",
       "      <td>-0.021488</td>\n",
       "      <td>0.255704</td>\n",
       "      <td>0.096954</td>\n",
       "      <td>-0.268662</td>\n",
       "      <td>-0.076848</td>\n",
       "      <td>-0.322715</td>\n",
       "      <td>-0.006281</td>\n",
       "      <td>0.256984</td>\n",
       "      <td>0.192531</td>\n",
       "      <td>-0.030673</td>\n",
       "      <td>-0.281496</td>\n",
       "      <td>-0.405527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176140</th>\n",
       "      <td>-0.240997</td>\n",
       "      <td>0.031357</td>\n",
       "      <td>0.281815</td>\n",
       "      <td>-0.305740</td>\n",
       "      <td>0.172148</td>\n",
       "      <td>0.110029</td>\n",
       "      <td>-0.201825</td>\n",
       "      <td>0.187842</td>\n",
       "      <td>0.270277</td>\n",
       "      <td>0.046374</td>\n",
       "      <td>-0.151114</td>\n",
       "      <td>-0.077195</td>\n",
       "      <td>0.185085</td>\n",
       "      <td>-0.411605</td>\n",
       "      <td>0.375458</td>\n",
       "      <td>-0.208552</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>-0.222556</td>\n",
       "      <td>-0.177022</td>\n",
       "      <td>-0.032289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176141 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           vec_1     vec_2     vec_3     vec_4     vec_5     vec_6     vec_7  \\\n",
       "0       0.285287  0.109443  0.128941  0.045603 -0.073157 -0.508928 -0.077453   \n",
       "1       0.401903  0.216579 -0.058514  0.164316 -0.153253 -0.301076 -0.462487   \n",
       "2       0.368750 -0.020495  0.121122 -0.052415 -0.222401 -0.037515 -0.128381   \n",
       "3       0.280957  0.323796  0.317315  0.034841 -0.129726 -0.239208 -0.543972   \n",
       "4       0.190432  0.059316  0.115147  0.262182 -0.142157 -0.138226 -0.540430   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "176136  0.310738  0.457551  0.094296 -0.086379  0.198949  0.233082  0.002009   \n",
       "176137  0.553510  0.014368  0.398847  0.006660  0.391471  0.252734 -0.076756   \n",
       "176138  0.378743  0.157006  0.343221  0.153644  0.187442  0.171272  0.170918   \n",
       "176139  0.378414  0.156319  0.247131  0.134425  0.170150  0.331544  0.077468   \n",
       "176140 -0.240997  0.031357  0.281815 -0.305740  0.172148  0.110029 -0.201825   \n",
       "\n",
       "           vec_8     vec_9    vec_10    vec_11    vec_12    vec_13    vec_14  \\\n",
       "0       0.125095  0.164354  0.147681  0.227378  0.228062 -0.065646 -0.018259   \n",
       "1       0.327744  0.033768  0.122843  0.067890 -0.172406 -0.026694 -0.313533   \n",
       "2       0.011114 -0.065411  0.389529  0.172736  0.221275  0.215809 -0.060970   \n",
       "3       0.237506  0.026008 -0.006228  0.134589 -0.047511 -0.054336 -0.222005   \n",
       "4       0.141701  0.132393  0.052895  0.025134  0.092645 -0.150749 -0.375577   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "176136  0.091956 -0.338310  0.011298 -0.097236 -0.065367 -0.017717  0.070351   \n",
       "176137  0.109708 -0.220743  0.096808 -0.091754 -0.265362 -0.044340  0.019195   \n",
       "176138  0.230688 -0.344162  0.292506  0.147863  0.147491  0.129362 -0.222961   \n",
       "176139  0.055609 -0.021488  0.255704  0.096954 -0.268662 -0.076848 -0.322715   \n",
       "176140  0.187842  0.270277  0.046374 -0.151114 -0.077195  0.185085 -0.411605   \n",
       "\n",
       "          vec_15    vec_16    vec_17    vec_18    vec_19    vec_20  \n",
       "0       0.589725  0.165162  0.243406  0.041697  0.047487 -0.080301  \n",
       "1       0.335412 -0.184949 -0.000822  0.093128  0.022665  0.142223  \n",
       "2       0.372512 -0.060175  0.251572  0.366057  0.229787  0.318017  \n",
       "3       0.227974 -0.272034  0.009888 -0.173518  0.228723  0.078310  \n",
       "4      -0.011666 -0.353730  0.131935 -0.431555  0.036446 -0.056576  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "176136  0.154885  0.079737  0.070983 -0.205526 -0.456746 -0.394401  \n",
       "176137  0.226361  0.026845  0.016040 -0.111859 -0.303012 -0.058567  \n",
       "176138  0.042992 -0.094266  0.091049 -0.224582  0.175517 -0.359527  \n",
       "176139 -0.006281  0.256984  0.192531 -0.030673 -0.281496 -0.405527  \n",
       "176140  0.375458 -0.208552  0.276112 -0.222556 -0.177022 -0.032289  \n",
       "\n",
       "[176141 rows x 20 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_df = pd.DataFrame([pd.Series(x) for x in df.vec])\n",
    "vec_df.columns = ['vec_{}'.format(x+1) for x in vec_df.columns]\n",
    "\n",
    "vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,vec_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covert into a csv\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='vectorized_data.csv')  \n",
    "df.to_csv('vectorized_data.zip', index=False,\n",
    "          compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
